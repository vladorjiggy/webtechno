<html>
<head>
<title></title>

</head>

<body>



<h2>Uebung 1</h2>
<br>
<p>Nr.1 a)</p>

<p>for (int i=0; i < samples;i++) {</p>			
				
   <p> System.out.println(readWavFile.sound[i]);</p>
<p>}</p>
<br><p>Musikaufnahme</p>

<audio controls><source src="./audio/Musik_Fetteng.wav" type="audio/wav"></audio>
    <br><p>Sprachaufnahme</p>
<audio controls><source src="./audio/Sprache_Fettang.wav" type="audio/wav"></audio>
<p>Nr.1 b)</p>
<br>
<p>Bei CDs wird eine Abtastrate von 44,1 kHz benutzt. Diese ist ausreichend, um Audiosignale mit Frequenzen bis 22 kHz zu erfassen. 
    Bei DVDs sind Abtastraten bis 96 und 192 kHz möglich. Durch die höheren Abtastraten können die notwendigen analogen Tiefpassfilter für das Antialiasing mit einem geringeren Gütefaktor arbeiten, was eine geringere Steilheit und damit weniger Verzerrungen bewirkt. Auch kann die Grenzfrequenz nach oben geschoben werden, sodass Audiosignale mit entsprechend höheren Frequenzen sauber übertragen werden. </p>
<br>

<p>c)</p>
<br>
<h4>Channels:</h4>
<p>Wieviele Kanäle nutzt das Audiosignal. 1 bei mono, 2 bei Stereo, 5 bei Dolby Surround</p>
<h4>Frames: </h4>
<p>Ein Frame besteht aus 588 Stereo-Samples. Eine Sekunde Audio besteht aus 75 Frames. Dies ergibt sich aus der Berechnung 75 x 588 = 44.100. Da die Samplerate des CD-Formats 44.100 Hz (Samples pro Sekunde) beträgt, entspricht dieser Wert einer Sekunde Audio. </p>
<h4>Sample Rate: </h4>
<p>Die Abtastrate oder Abtastfrequenz, auch Samplingrate, Samplerate oder Samplingfrequenz, ist in der Signalverarbeitung die Häufigkeit, mit der ein Analogsignal (auch zeitkontinuierliches Signal genannt) in einer vorgegebenen Zeit abgetastet (das heißt, gemessen und in ein zeitdiskretes Signal umgewandelt) wird. </p>
<h4>Valid Bits ( Bittiefe ) :</h4>
<p>Die Samplingtiefe, auch Bittiefe genannt, gibt die Anzahl der Bits an, die bei der Quantisierung eines analogen Signals pro Abtastwert (=Sample) verwendet werden. Sie bestimmt, in wie vielen Abstufungen die Amplitude repräsentiert werden kann. Die Samplingtiefe ist neben der Samplingrate der zweite Parameter, durch den der Digitalisierungsvorgang beschrieben wird. </p>
<h4>Bytes per Sample (Bitrate):</h4>
<p>Die Bitrate ist eine Datenübertragungsrate und bezeichnet die Ausgabemenge von Informationseinheiten bei digitalen Multimediaformaten im Verhältnis einer Datenmenge zu einer Zeit, typischerweise gemessen in Bit pro Sekunde, abgekürzt als Bit/s oder bps. Mit fortschreitender Technik sind je nach Themengebiet immer mehr Vielfache üblich, angefangen bei kbit/s oder kbps (1.000 Bit/s), weiter mit Mbit/s (1.000.000 Bit/s) und Gbit/s (1.000.000.000 Bit/s). </p>

<p>d)</p>
<br>
<p>Musikdatei:</p>
<p>D = 44100/5 = 8820 frames/s</p>

<br>
<p>Sprachdatei:</p>
<p>D = 16000/5 = 3200 frames/s</p>



<strong>Nr.2 a)</strong>

<h4>Source-Code</h4>
<p>  for (int i=0; i < samples;i++) {</p>	
<p>System.out.println(readWavFile.sound[i]);</p>   			
<p>}</p>
<br><p>sine_hi (Original)</p>
<audio controls><source src="./audio/sinus_hi_Fetteng.wav" type="audio/wav"></audio>
   

<p>Frequenz ( Sinus_LO ) = ca. 3000</p>
<p>Die Formel f0 = 1/T0 dient zur Bestimmung der Frequenz einer Schwingung.
    Die Frequenz der Schwingung "f0" und die Periodendauer "T0" der abgetastetend Schwingung stehen in Verhältnis zueinander.
    f0=1/n*Ta : durch die Multiplikation der Anzahl der Abtastwerte pro Schwingung n und des Abstands zwischen zwei Abtastwerten Ta wird T0 ermittelt.
     
    Ta=1/fa ---------> f0=1/n*fa  (Ableitung, da fa Abtastfrequenz)
    Teilt man die Anzahl der Abtastwerte durch die Anzahl der Schwingungen innerhalb einer Periode erhält man n.</p>
<img src="./images/sin_hi_screenshot.png" width="500px" height="500px">
<p>Sin_HI:</p>
<p>13623</p>
 <p>   16069</p>
 <p>   9102</p>
 <p>   -3196</p>
 <p>   -13623</p>
 <p>   -16069</p>
  <p>  -9102</p>
 <p>   3196</p>
  <p>  13623</p>
<br>

<audio controls><source src="./audio/sinus_lo_Fetteng.wav" type="audio/wav"></audio>
<p>Frequenz ( Sinus_HI ) =6 kHz</p>
<p>Begründung: Samplerate beträgt 16000 kHz. Diese teilt man durch die Anzahl der Samples in einer Amplitude. In diesem Fall wären das 3 Samples. Also 1/(8 / 3) *16 = 6kHz</p>
<img src="./images/sin_lo_screenshot.png" width="500px" height="500px">
<p>Sin_LO:</p>
<p>13623</p>
 <p>   16069</p>
 <p>   9102</p>
 <p>   -3196</p>
 <p>   -13623</p>
 <p>   -16069</p>
  <p>  -9102</p>
 <p>   3196</p>
  <p>  13623</p>
<br>

<audio controls><source src="./audio/sinus_lo_Fetteng.wav" type="audio/wav"></audio>
<p>Frequenz ( Sinus_LO ) =3 kHz</p>
<p>Begründung: Samplerate beträgt 16000 kHz. Diese teilt man durch die Anzahl der Samples in einer Amplitude. In diesem Fall wären das 3 Samples. Also 1/(16 / 3) *16 = 3kHz</p>

<h4>Nr.2 c</h4>
<p>Abtasttheorem: fa > 2x f0 max</p>
<p>Mathematische Vorschrift, die besagt, dass bei der Analog/Digital-Wandlung die Abtastfrequenz mehr als doppelt so hoch sein muss wie die höchste Frequenz des zu digitalisierenden analogen Signals. Die Abtastfrequenz eines Audiosignals muss demnach größer als 40 kHz, die Abtastfrequenz eines Videosignals in HD größer als 60 MHz und in SD größer als 10 MHz sein.

    Das Abtasttheorem wird auch Nyquist- oder Shannon-Theorem genannt.</p>

<img src="./images/abtasttherorem.png" alt="" srcset=""> 
  
<br>

<h4>Nr.2 d</h4>
<p>Die Vorbehandlung nennt sich Aliasing</p>
<p>Bei herkömmlichen Soundkarten wird Aliasing durch den Einsatz von Tiefpassfilter verhindert. Frequenzen, die >= fa / 2,  werden herausgefiltert, so wird das Abtasttheorem eingehalten</p>



<h4>Nr.2 e</h4>

<p>Original (LO)</p>
<audio controls><source src="./audio/sine_lo03.wav" type="audio/wav"></audio>



<h4>Nr.2 f</h4>

<br>
<p>LO:</p>

<p>nach Downsampling (LO)</p>
<audio controls><source src="./audio/sinus_lo_Fetteng.wav" type="audio/wav"></audio>
<img src="./images/nach_downsampling_lo.png" width="500px" height="250px">
<p>Frequenz: 6000Hz</p>


<p>Original (HI)</p>
<audio controls><source src="./audio/sine_hi05.wav" type="audio/wav"></audio>



<p>HI:</p>
<p>nach Downsampling (HI)</p>
<audio controls><source src="./audio/sinus_hi_Fetteng.wav" type="audio/wav"></audio>
<img src="./images/nach_downsampling_hi.png" width="500px" height="250px">
<p>Frequenz: 2000Hz</p>

    
    <h4>Nr.3 a</h4>
    <p>Bei 16 bit Auflösung ist die höchstmögliche Anzahl der darstellbaren Amplitudenwerte 216=65536 und bei 8 bit Auflösung sind es 28=256.</p>

    <h4>Nr.3 b</h4>
    <p>for (int i=0; i < samples;i++) {</p>
			
        <p>readWavFile.sound[i] = (short) ((int) (readWavFile.sound[i] / Math.pow(2, reduced_bits)) * Math.pow(2, reduced_bits));</p>
        
    <p>}</p>
    <h5>Sprache:</h5>
    <table>
        <tr>
            <td style="width: 500px;"><audio controls><source src="./audio/sprache_14.wav" type="audio/wav"></audio><p>Originalaufnahme.</p><br></td>   
            <td style="width: 500px;"><audio controls><source src="./audio/output_sprache_4bit_aufgabe3b.wav" type="audio/wav"></audio><p>Aufnahme mit 4 Bit Reduktion.</p><br></td>
            <td style="width: 500px;"><audio controls><source src="./audio/output_sprache_12bit_aufgabe3b.wav" type="audio/wav"></audio><p>Aufnahme mit 12 Bit Reduktion.</p><br></td>
        </tr>
        <a href="./images/sprache_original.png"><img src="./images/sprache_original.png" width="500px" height="250px"><a>
        <a href="./images/sprache_4bit_reduziert.png"><img src="./images/sprache_4bit_reduziert.png" width="500px" height="250px"></a>
        <a href="./images/sprache_12bit_reduziert.png"><img src="./images/sprache_12bit_reduziert.png" width="500px" height="250px"></a>
        
    </table>
    <ol>
        <p>Die obige Grafik zeigt die Bitreduktion der monoton Sprachaufnahme im Originalzustand (links),
            der Aufnahme mit 4 Bit Reduktion (12 Bit verbleibend) und der Aufnahme mit 12 Bit Reduktion (4 Bit verbleibend)
        Wie in der Grafik zu sehen ist, sind die Unterschiede azwischen der Orginalaufnahme und der 4 Bit reduzierten Aufnahme maginal. 
            Große unterschiede sind jedoch auf der 12 Bit reduzierten Aufnahme zu erkennen. 
        Bei dieser ist die Stimme kaum noch zu verstehen. Auch im Spektrogramm ist dies deutlich zu erkennen, da die entweder sehr starke Ausschläge auftreten, 
            oder im Orginal vorhandene Frequenzen jetzt nicht mehr vorliegen. 
        </p>
    </ol>

    <h5>Musik:</h5>
    <table>
        <tr>
            <td style="width: 500px;"><audio controls><source src="./audio/Musik_Fetteng.wav" type="audio/wav"></audio><p>Originalaufnahme.</p><br></td>   
            <td style="width: 500px;"><audio controls><source src="./audio/output_musik_4bit_aufgabe3b.wav" type="audio/wav"></audio><p>Aufnahme mit 4 Bit Reduktion.</p><br></td>
            <td style="width: 500px;"><audio controls><source src="./audio/output_musik_12bit_aufgabe3b.wav" type="audio/wav"></audio><p>Aufnahme mit 12 Bit Reduktion.</p><br></td>
        </tr>
        <a href="./images/musik_original.png"><img src="./images/musik_original.png" width="500px" height="250px"></a>
        <a href="./images/musik_4bit_reduziert.png"><img src="./images/musik_4bit_reduziert.png" width="500px" height="250px"></a>
        <a href="./images/musik_12bit_reduziert.png"><img src="./images/musik_12bit_reduziert.png" width="500px" height="250px"></a> 
        
        
    </table>
    <ol>
        <li>Die obige Grafik zeigt die Bitreduktion der Musikaufnahme im Originalzustand (links), der Aufnahme mit 4 Bit Reduktion (12 Bit verbleibend)
            und der Aufnahme mit 12 Bit Reduktion (4 Bit verbleibend)</li>
        <li>Im Gegensatz zur Sprachaufnahme, ist selbst bei 12 Bit Reduktion (also 4 Bit verbleibend) die Musik deutlich zu hören, auch wenn eine sehr starke Störung wahrnehmbar ist. </li> 
        <li>Die Unterschiede hinsichtlich der Auswirkungen der Bitreduktion auf Musik und Sprache werden damit Begründet, dass bei der Musik eine durchgehende Geräuschkulisse geschaffen 
            wird und somit ein dichteres Spektrum hinsichtlich Frequenz und Lautstärke erreicht wird. Der durch die Bitreduktion entstehende Fehler wird somit zwar hörbar, aber es stehen 
            noch genug Informationen zur Verfügung. Aufgrund der starken Schwankungen bei der Sprache und der fehlenden Durchgängigkeit wirkt sich ein auftretender Fehler somit stärker aus.
        </li>
    </ol>

    <h3>Aufgabe 3d)</h3>
       
        
        <p>
            Besonders störend ist das Rauschen, welches entsteht. Es wirkt zunächst im Hintergrund und verlagert sich "gefühlt" mit zunehmender Reduktion immer weiter in den Vordergrund, 
            bis zuletzte die Musik / Sprache kaum bis gar nicht mehr zu verstehen ist. 
        </p>


    <h3>Aufgabe 3 e)</h3>
    <p> short[] new_wave = new short[samples];</p>
       <p> for(int i=0;i < samples;i++) </p>
       <p>{</p>
            <p>new_wave [i]=readWavFile.sound[i]; </p> 
                <p>readWavFile.sound[i]/=16384; </p>           
                    <p>readWavFile.sound[i]*=16384;  </p>          
                        <p>readWavFile.sound[i]-= new_wave[i];</p>      
                            <p> readWavFile.sound[i]*=2;    </p>                  
        <p>}</p>
        <p>
            Besonders störend ist das Rauschen, welches entsteht. Es wirkt zunächst im Hintergrund und verlagert sich "gefühlt" mit zunehmender Reduktion immer weiter in den Vordergrund, 
            bis zuletzte die Musik / Sprache kaum bis gar nicht mehr zu verstehen ist. 
        </p>
</body>
</html>
